{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bag_file(file_name):\n",
    "    pipe = rs.pipeline()\n",
    "    cfg = rs.config()\n",
    "    cfg.enable_device_from_file(file_name, repeat_playback=False)\n",
    "    profile = pipe.start(cfg)\n",
    "    playback = profile.get_device().as_playback()\n",
    "    playback.set_real_time(False) # False: no frame drop\n",
    "\n",
    "    return pipe, cfg, profile, playback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video duration:  0:00:41.604937\n"
     ]
    }
   ],
   "source": [
    "# Read the bag file\n",
    "file_name = \"..\\Dataset\\_realsense\\Data_realsense1/20240322_123504.bag\"\n",
    "pipe, cfg, profile, playback = read_bag_file(file_name)\n",
    "duration = playback.get_duration()\n",
    "print(\"Video duration: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to align the depth frame to the color frame\n",
    "def align_frames(frames):\n",
    "    align = rs.align(rs.stream.color)\n",
    "    aligned_frames = align.process(frames)\n",
    "    aligned_depth = aligned_frames.get_depth_frame()\n",
    "    aligned_color = aligned_frames.get_color_frame()\n",
    "    return aligned_depth, aligned_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of frames:  123\n"
     ]
    }
   ],
   "source": [
    "colorizer = rs.colorizer()\n",
    "\n",
    "# Read the full stream\n",
    "pipe, cfg, profile, playback = read_bag_file(file_name)\n",
    "num_frames = 0\n",
    "wait_key = 1\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = pipe.wait_for_frames()\n",
    "\n",
    "        # Align the depth frame to color frame so they have the same shape\n",
    "        aligned_depth, aligned_color = align_frames(frames)\n",
    "        depth_color_frame = colorizer.colorize(aligned_depth)\n",
    "\n",
    "        depth_color_image = np.asanyarray(depth_color_frame.get_data())\n",
    "        color_image = np.asanyarray(aligned_color.get_data())\n",
    "\n",
    "        # Stack both images horizontally\n",
    "        images = np.hstack((color_image, depth_color_image))\n",
    "        cv2.imshow(\"Images\", images)\n",
    "\n",
    "        key = cv2.waitKey(wait_key)\n",
    "\n",
    "        # Press esc close the image window\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "        # Press s to write the color_image on disk\n",
    "        if key == ord('s'):\n",
    "            cv2.imwrite(\"./color_images/color_image\" + str(num_frames) + \".png\", color_image)\n",
    "\n",
    "        # Press d to view the video frame by frame\n",
    "        if key == ord('d'):\n",
    "            if wait_key == 0:\n",
    "                wait_key = 1\n",
    "            else:\n",
    "                wait_key = 0\n",
    "\n",
    "        num_frames += 1\n",
    "\n",
    "# Catch exception if the stream is ended\n",
    "except RuntimeError:\n",
    "    print(\"Stream ended\")\n",
    "        \n",
    "finally:\n",
    "    # Stop streaming\n",
    "    cv2.destroyAllWindows()\n",
    "    pipe.stop()\n",
    "\n",
    "print(\"Total number of frames: \", num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask to remove the walls on the depth map\n",
    "#mask = np.zeros(frame_shape, dtype=\"uint8\")\n",
    "#cv2.rectangle(mask, (0, 316), (223, 480), (255, 255, 255), -1) # left wall\n",
    "#cv2.rectangle(mask, (0, 316), (223, 480), (255, 255, 255), -1) # right wall\n",
    "#mask = 255 - mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract height of the participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the aruco detector\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_ARUCO_MIP_36h12)\n",
    "aruco_params = cv2.aruco.DetectorParameters()\n",
    "\n",
    "aruco_params.adaptiveThreshConstant = 3 # lower -> more aggresive, default 7\n",
    "aruco_params.errorCorrectionRate = 0.2 # default 0.6\n",
    "aruco_params.polygonalApproxAccuracyRate = 0.05 # default 0.03\n",
    "\n",
    "detector = cv2.aruco.ArucoDetector(aruco_dict, aruco_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream ended\n"
     ]
    }
   ],
   "source": [
    "camera_height = 2.65 # meters\n",
    "\n",
    "pipe, cfg, profile, playback = read_bag_file(file_name)\n",
    "num_frames = 0\n",
    "wait_key = 1\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipe.wait_for_frames()\n",
    "        # Align the depth frame to color frame so they have the same shape\n",
    "        aligned_depth, aligned_color = align_frames(frames)\n",
    "\n",
    "        color_image = np.asanyarray(aligned_color.get_data())\n",
    "\n",
    "        output = color_image.copy()\n",
    "        corners, ids, rejected = detector.detectMarkers(color_image)\n",
    "        cv2.aruco.drawDetectedMarkers(output, corners, ids)\n",
    "\n",
    "        if len(corners) > 0:\n",
    "            # Get the distance value at the center of the marker\n",
    "            c = corners[0][0]\n",
    "            center_x = int((c[0][0] + c[1][0] + c[2][0] + c[3][0]) / 4)\n",
    "            center_y = int((c[0][1] + c[1][1] + c[2][1] + c[3][1]) / 4)\n",
    "            distance = aligned_depth.get_distance(center_x, center_y)\n",
    "\n",
    "            participant_height = camera_height - distance # meters\n",
    "\n",
    "            # Draw the distance value on the image\n",
    "            cv2.putText(output, \"Height: {:.2f} m\".format(participant_height), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.imwrite(\"./distance_images/distance_image\" + str(num_frames) + \".png\", output)\n",
    "\n",
    "        cv2.imshow(\"Output\", output)\n",
    "        key = cv2.waitKey(wait_key)\n",
    "\n",
    "        # Press esc close the image window\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "        # Press d to view the video frame by frame\n",
    "        if key == ord('d'):\n",
    "            if wait_key == 0:\n",
    "                wait_key = 1\n",
    "            else:\n",
    "                wait_key = 0\n",
    "\n",
    "        num_frames += 1\n",
    "           \n",
    "# Catch exception if the stream is ended\n",
    "except RuntimeError:\n",
    "    print(\"Stream ended\")\n",
    "        \n",
    "finally:\n",
    "    # Stop streaming\n",
    "    cv2.destroyAllWindows()\n",
    "    pipe.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
