{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bag_file(file_name):\n",
    "    pipe = rs.pipeline()\n",
    "    cfg = rs.config()\n",
    "    cfg.enable_device_from_file(file_name, repeat_playback=False)\n",
    "    profile = pipe.start(cfg)\n",
    "    playback = profile.get_device().as_playback()\n",
    "    playback.set_real_time(False) # False: no frame drop\n",
    "    \n",
    "    # Get the frame shape of the color sensor\n",
    "    frames = pipe.wait_for_frames()\n",
    "    color_frame = frames.get_color_frame()\n",
    "    frame_shape = (color_frame.get_height(), color_frame.get_width())\n",
    "\n",
    "    return pipe, cfg, profile, playback, frame_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video duration:  0:01:16.408926\n",
      "Frame shape:  (480, 640)\n"
     ]
    }
   ],
   "source": [
    "# Read the bag file\n",
    "# file_name = \"..\\\\Dataset\\\\_realsense\\\\Data_realsense1\\\\20240322_123504.bag\"\n",
    "# file_name = \"..\\\\Dataset\\\\tests\\\\60fps_424x240.bag\"\n",
    "file_name = \"..\\\\Dataset\\\\tests\\\\60fps_640x480.bag\"\n",
    "\n",
    "pipe, cfg, profile, playback, frame_shape = read_bag_file(file_name)\n",
    "duration = playback.get_duration()\n",
    "print(\"Video duration: \", duration)\n",
    "print(\"Frame shape: \", frame_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to align the depth frame to the color frame\n",
    "def align_frames(frames):\n",
    "    align = rs.align(rs.stream.color)\n",
    "    aligned_frames = align.process(frames)\n",
    "    aligned_depth = aligned_frames.get_depth_frame()\n",
    "    aligned_color = aligned_frames.get_color_frame()\n",
    "    return aligned_depth, aligned_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of frames:  77\n"
     ]
    }
   ],
   "source": [
    "colorizer = rs.colorizer()\n",
    "\n",
    "# Read the full stream\n",
    "pipe, cfg, profile, playback, frame_shape = read_bag_file(file_name)\n",
    "num_frames = 0\n",
    "wait_key = 1\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = pipe.wait_for_frames()\n",
    "\n",
    "        # Align the depth frame to color frame so they have the same shape\n",
    "        aligned_depth, aligned_color = align_frames(frames)\n",
    "        depth_color_frame = colorizer.colorize(aligned_depth)\n",
    "\n",
    "        depth_color_image = np.asanyarray(depth_color_frame.get_data())\n",
    "        color_image = np.asanyarray(aligned_color.get_data())\n",
    "\n",
    "        # Stack both images horizontally\n",
    "        images = np.hstack((color_image, depth_color_image))\n",
    "        cv2.imshow(\"Images\", images)\n",
    "\n",
    "        key = cv2.waitKey(wait_key)\n",
    "\n",
    "        # Press esc close the image window\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "        # Press s to write the color_image on disk\n",
    "        if key == ord('s'):\n",
    "            cv2.imwrite(\".\\color_images\\motion_blur\" + str(num_frames) + \".png\", color_image)\n",
    "            cv2.imwrite(\".\\depth_images\\image\" + str(num_frames) + \".png\", depth_color_image)\n",
    "\n",
    "        # Press d to view the video frame by frame\n",
    "        if key == ord('d'):\n",
    "            if wait_key == 0:\n",
    "                wait_key = 1\n",
    "            else:\n",
    "                wait_key = 0\n",
    "\n",
    "        num_frames += 1\n",
    "\n",
    "# Catch exception if the stream is ended\n",
    "except RuntimeError:\n",
    "    print(\"Stream ended\")\n",
    "        \n",
    "finally:\n",
    "    # Stop streaming\n",
    "    cv2.destroyAllWindows()\n",
    "    pipe.stop()\n",
    "\n",
    "print(\"Total number of frames: \", num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract height of the participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a mask to remove the top part of the image\n",
    "mask = np.zeros(frame_shape, dtype=np.uint8)\n",
    "cv2.rectangle(mask, (0, 0), (424, 120), (255, 255, 255), -1)\n",
    "mask = cv2.bitwise_not(mask)\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the aruco detector\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_ARUCO_MIP_36h12)\n",
    "aruco_params = cv2.aruco.DetectorParameters()\n",
    "\n",
    "aruco_params.polygonalApproxAccuracyRate = 0.05\n",
    "aruco_params.errorCorrectionRate = 0.2\n",
    "\n",
    "detector = cv2.aruco.ArucoDetector(aruco_dict, aruco_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign(p1, p2, p3):\n",
    "    return (p1[0] - p3[0]) * (p2[1] - p3[1]) - (p2[0] - p3[0]) * (p1[1] - p3[1])\n",
    "\n",
    "def is_inside(p, a, b, c, d):\n",
    "    b1 = sign(p, a, b) < 0.0\n",
    "    b2 = sign(p, b, c) < 0.0\n",
    "    b3 = sign(p, c, d) < 0.0\n",
    "    b4 = sign(p, d, a) < 0.0\n",
    "    return ((b1 == b2) and (b2 == b3) and (b3 == b4))\n",
    "\n",
    "def is_point_in_square(A, B, C, D, P):\n",
    "    return is_inside(P, A, B, C, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_height = 2.49 # meters \n",
    "\n",
    "pipe, cfg, profile, playback, frame_shape = read_bag_file(file_name)\n",
    "num_frames = 0\n",
    "wait_key = 1\n",
    "\n",
    "# Empty the distance_images folder\n",
    "files = glob.glob('distance_images/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "# Data structure to store the a list of height for every aruco code id\n",
    "heights = {}\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipe.wait_for_frames()\n",
    "        # Align the depth frame to color frame so they have the same shape\n",
    "        aligned_depth, aligned_color = align_frames(frames)\n",
    "\n",
    "        color_image = np.asanyarray(aligned_color.get_data())\n",
    "        # color_image = cv2.bitwise_and(color_image, color_image, mask=mask)\n",
    "\n",
    "        corners, ids, rejected = detector.detectMarkers(color_image)\n",
    "        output_image = color_image.copy()\n",
    "        cv2.aruco.drawDetectedMarkers(output_image, corners, ids)\n",
    "\n",
    "        for k in range(len(corners)):\n",
    "            c = corners[k][0]\n",
    "            A = c[0]\n",
    "            B = c[1]\n",
    "            C = c[2]\n",
    "            D = c[3]\n",
    "            distances = []\n",
    "\n",
    "            # Pick 100 random points inside the aruco code square to calculate the average distance\n",
    "            min_x = int(min(A[0], B[0], C[0], D[0]))\n",
    "            max_x = int(max(A[0], B[0], C[0], D[0]))\n",
    "            min_y = int(min(A[1], B[1], C[1], D[1]))\n",
    "            max_y = int(max(A[1], B[1], C[1], D[1]))\n",
    "\n",
    "            num_points = 0\n",
    "            while num_points < 100:\n",
    "                x = np.random.randint(min_x, max_x + 1) \n",
    "                y = np.random.randint(min_y, max_y + 1)\n",
    "                if is_point_in_square(A, B, C, D, (x, y)):\n",
    "                    # Draw the point on the image\n",
    "                    cv2.circle(output_image, (x, y), 2, (0, 255, 0), -1)\n",
    "                    z = aligned_depth.get_distance(x, y)\n",
    "                    distances.append(z)\n",
    "                    num_points += 1\n",
    "\n",
    "            distance = np.mean(distances)\n",
    "            height = camera_height - distance\n",
    "            cv2.putText(output_image, \"Height: {:.2f} m\".format(height), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            \n",
    "            if not ids[k][0] in heights:\n",
    "                heights[ids[k][0]] = []\n",
    "                \n",
    "            heights[ids[k][0]].append(height)\n",
    "\n",
    "        cv2.imshow(\"Output\", output_image)\n",
    "        key = cv2.waitKey(wait_key)\n",
    "\n",
    "        # Press esc close the image window\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "        # Press d to view the video frame by frame\n",
    "        if key == ord('d'):\n",
    "            if wait_key == 0:\n",
    "                wait_key = 1\n",
    "            else:\n",
    "                wait_key = 0\n",
    "\n",
    "        num_frames += 1\n",
    "           \n",
    "# Catch exception if the stream is ended\n",
    "# except RuntimeError:\n",
    "#     print(\"Stream ended\")\n",
    "        \n",
    "finally:\n",
    "    # Stop streaming\n",
    "    cv2.destroyAllWindows()\n",
    "    pipe.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{87: 1.8944999516010284, 24: 1.8134999513626098, 19: 1.8796249717473983, 67: 1.904999962945779}\n"
     ]
    }
   ],
   "source": [
    "def remove_outliers(data, m=2):\n",
    "    # Z-score method\n",
    "    data = np.array(data)\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    filtered_data = [x for x in data if abs(x - mean) / std < m]\n",
    "    return filtered_data\n",
    "\n",
    "def calculate_mean_height(heights):\n",
    "    mean_heights = {}\n",
    "\n",
    "    for key, height_list in heights.items():\n",
    "        filtered_heights = remove_outliers(height_list)\n",
    "        if filtered_heights:\n",
    "            mean_heights[key] = np.mean(filtered_heights)\n",
    "\n",
    "    return mean_heights\n",
    "\n",
    "# Remove outliers and calculate the mean height for each aruco code id\n",
    "mean_heights = calculate_mean_height(heights)\n",
    "print(mean_heights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attemping to enhance Aruco codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_height = 2.65 # meters => NOT SURE ABOUT THIS VALUE\n",
    "\n",
    "pipe, cfg, profile, playback, frame_shape = read_bag_file(file_name)\n",
    "num_frames = 0\n",
    "wait_key = 1\n",
    "\n",
    "# Empty the distance_images folder\n",
    "files = glob.glob('distance_images/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "# Data structure to store the a list of height for every aruco code id\n",
    "heights = {}\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipe.wait_for_frames()\n",
    "\n",
    "        # Align the depth frame to color frame so they have the same shape\n",
    "        aligned_depth, aligned_color = align_frames(frames)\n",
    "        color_image = np.asanyarray(aligned_color.get_data())\n",
    "        depth_color_frame = colorizer.colorize(aligned_depth)\n",
    "        depth_color_image = np.asanyarray(depth_color_frame.get_data())\n",
    "\n",
    "        # Apply the mask to the depth image\n",
    "        depth_color_image = cv2.bitwise_and(depth_color_image, depth_color_image, mask=mask)\n",
    "\n",
    "        # Convert the image to HSV color space\n",
    "        hsv_image = cv2.cvtColor(depth_color_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Define the range for red color in HSV\n",
    "        # Note: Red can appear in two ranges in HSV\n",
    "        lower_red1 = np.array([0, 70, 50])\n",
    "        upper_red1 = np.array([10, 255, 255])\n",
    "        lower_red2 = np.array([170, 70, 50])\n",
    "        upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "        # Create masks for red color\n",
    "        red_mask1 = cv2.inRange(hsv_image, lower_red1, upper_red1)\n",
    "        red_mask2 = cv2.inRange(hsv_image, lower_red2, upper_red2)\n",
    "\n",
    "        # Combine the two masks\n",
    "        red_mask = cv2.bitwise_or(red_mask1, red_mask2)\n",
    "\n",
    "        # Apply the mask to the original image\n",
    "        result = cv2.bitwise_and(depth_color_image, depth_color_image, mask=red_mask)\n",
    "\n",
    "        # Convert the result to grayscale and apply thresholding\n",
    "        gray_result = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh_result = cv2.threshold(gray_result, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        # Apply the closing morphological operation to fill in holes\n",
    "        kernel = np.ones((30, 30), np.uint8)\n",
    "        closed_result = cv2.morphologyEx(thresh_result, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # Find contours of the red square\n",
    "        contours, _ = cv2.findContours(closed_result, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Create a mask to keep only the aruco code in the color image\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > 100*100 and area < 200*200:\n",
    "                x, y, w, h = cv2.boundingRect(contour)  \n",
    "                arcuo_code_mask = np.zeros(frame_shape, dtype=np.uint8)\n",
    "                \n",
    "                # Expand the bounding box by 50 pixels\n",
    "                sz = (w + h) // 2\n",
    "                x1 = max(0, x - 25)\n",
    "                y1 = max(0, y - 25)\n",
    "                x2 = min(640, x + sz + 25)\n",
    "                y2 = min(480, y + sz + 25)\n",
    "                cv2.rectangle(arcuo_code_mask, (x1, y1), (x2, y2), (255, 255, 255), -1)\n",
    "                color_image = cv2.bitwise_and(color_image, color_image, mask=arcuo_code_mask)\n",
    "\n",
    "                cv2.imwrite(\"color_images\\motion_blur_mask\\motion_blur\" + str(num_frames) + \".png\", color_image)\n",
    "\n",
    "        cv2.imshow(\"Output\", color_image)\n",
    "        key = cv2.waitKey(wait_key)\n",
    "\n",
    "        # Press esc close the image window\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "        # Press d to view the video frame by frame\n",
    "        if key == ord('d'):\n",
    "            if wait_key == 0:\n",
    "                wait_key = 1\n",
    "            else:\n",
    "                wait_key = 0\n",
    "\n",
    "        num_frames += 1\n",
    "           \n",
    "# Catch exception if the stream is ended\n",
    "except RuntimeError:\n",
    "    print(\"Stream ended\")\n",
    "        \n",
    "finally:\n",
    "    # Stop streaming\n",
    "    cv2.destroyAllWindows()\n",
    "    pipe.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.imread(\"color_images\\motion_blur\\motion_blur1229.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# corners, ids, rejected = detector.detectMarkers(image)\n",
    "# output_image = image.copy()\n",
    "# if corners is not None:\n",
    "#     print(\"Detected markers: \", len(corners))\n",
    "\n",
    "# cv2.aruco.drawDetectedMarkers(output_image, corners, ids)\n",
    "# cv2.imshow(\"Output\", output_image)\n",
    "\n",
    "# # Show the marker id image\n",
    "# marker_id = ids[0][0]\n",
    "# print(\"Marker ID: \", marker_id)\n",
    "# marker_size = 200  # Taille de l'image générée\n",
    "# aruco_marker_image = cv2.aruco.generateImageMarker(aruco_dict, marker_id, marker_size)\n",
    "# cv2.imshow(\"Marker\", aruco_marker_image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
