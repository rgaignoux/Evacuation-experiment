{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bag_file(file_name):\n",
    "    pipe = rs.pipeline()\n",
    "    cfg = rs.config()\n",
    "    cfg.enable_device_from_file(file_name, repeat_playback=False)\n",
    "    profile = pipe.start(cfg)\n",
    "    playback = profile.get_device().as_playback()\n",
    "    playback.set_real_time(False) # False: no frame drop\n",
    "    \n",
    "    # Get the frame shape of the color sensor\n",
    "    frames = pipe.wait_for_frames()\n",
    "    color_frame = frames.get_color_frame()\n",
    "    frame_shape = (color_frame.get_height(), color_frame.get_width())\n",
    "\n",
    "    return pipe, cfg, profile, playback, frame_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video duration:  0:00:43.503743\n",
      "Frame shape:  (480, 848)\n"
     ]
    }
   ],
   "source": [
    "# Read the bag file\n",
    "# file_name = \"..\\\\Dataset\\\\_realsense\\\\Data_realsense1\\\\20240322_123504.bag\"\n",
    "#file_name = \"..\\\\..\\\\Dataset\\\\tests\\\\20240620_113148.bag\"\n",
    "file_name = \"..\\\\bag_records\\\\me_and_sasa.bag\"\n",
    "\n",
    "pipe, cfg, profile, playback, frame_shape = read_bag_file(file_name)\n",
    "duration = playback.get_duration()\n",
    "print(\"Video duration: \", duration)\n",
    "print(\"Frame shape: \", frame_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_depth_frame(depth_frame):\n",
    "    # Post processing possible only on the depth_frame\n",
    "    assert (depth_frame.is_depth_frame())\n",
    "\n",
    "    decimation_magnitude = 1.0\n",
    "    spatial_magnitude = 2.0\n",
    "    spatial_smooth_alpha = 0.5\n",
    "    spatial_smooth_delta = 20\n",
    "    temporal_smooth_alpha = 0.4\n",
    "    temporal_smooth_delta = 20\n",
    "\n",
    "    # Available filters\n",
    "    decimation_filter = rs.decimation_filter()\n",
    "    depth_to_disparity = rs.disparity_transform(True)\n",
    "    spatial_filter = rs.spatial_filter()\n",
    "    temporal_filter = rs.temporal_filter()\n",
    "    disparity_to_depth = rs.disparity_transform(False)\n",
    "\n",
    "    # Options for hole_filling_filter\n",
    "    # 0 - fill_from_left - Use the value from the left neighbor pixel to fill the hole\n",
    "    # 1 - farest_from_around - Use the value from the neighboring pixel which is furthest away from the sensor\n",
    "    # 2 - nearest_from_around - Use the value from the neighboring pixel closest to the sensor\n",
    "    hole_filling = rs.hole_filling_filter(1)\n",
    "\n",
    "    # Apply the control parameters for the filters\n",
    "    decimation_filter.set_option(rs.option.filter_magnitude, decimation_magnitude)\n",
    "    spatial_filter.set_option(rs.option.filter_magnitude, spatial_magnitude)\n",
    "    spatial_filter.set_option(rs.option.filter_smooth_alpha, spatial_smooth_alpha)\n",
    "    spatial_filter.set_option(rs.option.filter_smooth_delta, spatial_smooth_delta)\n",
    "    temporal_filter.set_option(rs.option.filter_smooth_alpha, temporal_smooth_alpha)\n",
    "    temporal_filter.set_option(rs.option.filter_smooth_delta, temporal_smooth_delta)\n",
    "\n",
    "    # Apply the filters\n",
    "    # Post processing order : https://dev.intelrealsense.com/docs/post-processing-filters\n",
    "    # Depth Frame >> Decimation Filter >> Depth2Disparity Transform >> Spatial Filter \n",
    "    # >> Temporal Filter >> Disparity2Depth Transform >> Hole Filling Filter >> Filtered Depth\n",
    "    filtered_frame = decimation_filter.process(depth_frame)\n",
    "    filtered_frame = depth_to_disparity.process(filtered_frame)\n",
    "    filtered_frame = spatial_filter.process(filtered_frame)\n",
    "    filtered_frame = temporal_filter.process(filtered_frame)\n",
    "    filtered_frame = disparity_to_depth.process(filtered_frame)\n",
    "    filtered_frame = hole_filling.process(filtered_frame)\n",
    "    \n",
    "    # Cast to depth_frame so that we can use the get_distance method afterwards\n",
    "    depth_frame_filtered = filtered_frame.as_depth_frame()\n",
    "\n",
    "    return depth_frame_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of frames:  49\n"
     ]
    }
   ],
   "source": [
    "colorizer = rs.colorizer()\n",
    "value_min = 0.0 # 0 meters\n",
    "value_max = 1.5 # 1.5 meters\n",
    "colorizer.set_option(rs.option.min_distance, value_min)\n",
    "colorizer.set_option(rs.option.max_distance, value_max)\n",
    "\n",
    "align = rs.align(rs.stream.color)\n",
    "\n",
    "# Read the full stream\n",
    "pipe, cfg, profile, playback, frame_shape = read_bag_file(file_name)\n",
    "num_frames = 0\n",
    "wait_key = 1\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Get frameset of color and depth\n",
    "        frames = pipe.wait_for_frames()\n",
    "\n",
    "        # Align the depth frame to color frame\n",
    "        aligned_frames = align.process(frames)\n",
    "\n",
    "        # Get aligned frames\n",
    "        aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "        color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "        # Validate that both frames are valid\n",
    "        if not aligned_depth_frame or not color_frame:\n",
    "            continue\n",
    "\n",
    "        # Post process is not included in the BAG file, so we need to apply it\n",
    "        depth_frame = post_process_depth_frame(aligned_depth_frame)\n",
    "\n",
    "        # Colorize the depth frame\n",
    "        depth_color_frame = colorizer.colorize(depth_frame)\n",
    "\n",
    "        depth_color_image = np.asanyarray(depth_color_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        cv2.imshow(\"Color Image\", color_image)\n",
    "        cv2.imshow(\"Depth Image\", depth_color_image)\n",
    "\n",
    "        key = cv2.waitKey(wait_key)\n",
    "\n",
    "        # Press esc close the image window\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "        # Press s to write the color_image on disk\n",
    "        if key == ord('s'):\n",
    "            cv2.imwrite(\".\\\\images\\\\color_images\\\\images\\\\color_\" + str(num_frames) + \".png\", color_image)\n",
    "            cv2.imwrite(\".\\\\images\\\\depth_images\\\\depth_\" + str(num_frames) + \".png\", depth_color_image)\n",
    "\n",
    "        # Press d to view the video frame by frame\n",
    "        if key == ord('d'):\n",
    "            if wait_key == 0:\n",
    "                wait_key = 1\n",
    "            else:\n",
    "                wait_key = 0\n",
    "\n",
    "        num_frames += 1\n",
    "\n",
    "# Catch exception if the stream is ended\n",
    "except RuntimeError:\n",
    "    print(\"Stream ended\")\n",
    "        \n",
    "finally:\n",
    "    # Stop streaming\n",
    "    cv2.destroyAllWindows()\n",
    "    pipe.stop()\n",
    "\n",
    "print(\"Total number of frames: \", num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract height of the participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a mask to keep ony the ROI, under the camera\n",
    "# mask = np.zeros(frame_shape, dtype=np.uint8)\n",
    "# center_y, center_x = frame_shape[0] // 2, frame_shape[1] // 2\n",
    "\n",
    "# # Mask size\n",
    "# half_height = frame_shape[0] // 3\n",
    "# top_left = (0, half_height)\n",
    "# bottom_right = (848, 480)\n",
    "\n",
    "# cv2.rectangle(mask, top_left, bottom_right, 255, thickness=-1)\n",
    "\n",
    "# plt.imshow(mask, cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the aruco detector\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_ARUCO_MIP_36h12)\n",
    "aruco_params = cv2.aruco.DetectorParameters()\n",
    "\n",
    "aruco_params.errorCorrectionRate = 0.2 # default 0.6\n",
    "aruco_params.polygonalApproxAccuracyRate = 0.05 # default 0.03\n",
    "\n",
    "detector = cv2.aruco.ArucoDetector(aruco_dict, aruco_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_height = 2.568 # meters, ground truth\n",
    "\n",
    "pipe, cfg, profile, playback, frame_shape = read_bag_file(file_name)\n",
    "num_frames = 0\n",
    "wait_key = 1\n",
    "\n",
    "# Data structure to store the a list of height for every aruco marker id\n",
    "heights = {}\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Get frameset of color and depth\n",
    "        frames = pipe.wait_for_frames()\n",
    "\n",
    "        # Align the depth frame to color frame\n",
    "        aligned_frames = align.process(frames)\n",
    "\n",
    "        # Get aligned frames\n",
    "        aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "        color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "        # Validate that both frames are valid\n",
    "        if not aligned_depth_frame or not color_frame:\n",
    "            continue\n",
    "\n",
    "        # Post process is not included in the BAG file, so we need to apply it\n",
    "        depth_frame = post_process_depth_frame(aligned_depth_frame)\n",
    "\n",
    "        # Colorize the depth frame\n",
    "        depth_color_frame = colorizer.colorize(depth_frame)\n",
    "\n",
    "        depth_color_image = np.asanyarray(depth_color_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        # Detect the aruco markers\n",
    "        corners, ids, rejected = detector.detectMarkers(color_image)\n",
    "        output_image = depth_color_image.copy()\n",
    "        cv2.aruco.drawDetectedMarkers(output_image, corners, ids)\n",
    "\n",
    "        for k in range(len(corners)):\n",
    "            id = ids[k][0]\n",
    "            c = corners[k][0]\n",
    "\n",
    "            # Calculate the distance using the center of the aruco marker\n",
    "            x = int(c[:, 0].sum() / 4)\n",
    "            y = int(c[:, 1].sum() / 4)\n",
    "            distance = depth_frame.get_distance(x, y)\n",
    "\n",
    "            # Calculate the height\n",
    "            height = camera_height - distance\n",
    "\n",
    "            # Display the height with an offset to avoid overlap\n",
    "            text_position_y = 30 + k * 40\n",
    "            cv2.putText(output_image, \"ID: {} Height: {:.2f}m\".format(id, height), (10, text_position_y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Store the height for the aruco marker id\n",
    "            if not id in heights:\n",
    "                heights[id] = []\n",
    "                \n",
    "            heights[id].append(height)\n",
    "\n",
    "        cv2.imshow(\"Output\", output_image)\n",
    "        cv2.imshow(\"Color Image\", color_image)\n",
    "        key = cv2.waitKey(wait_key)\n",
    "\n",
    "        # Press esc close the image window\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "        # Press d to view the video frame by frame\n",
    "        if key == ord('d'):\n",
    "            if wait_key == 0:\n",
    "                wait_key = 1\n",
    "            else:\n",
    "                wait_key = 0\n",
    "\n",
    "        num_frames += 1\n",
    "           \n",
    "# Catch exception if the stream is ended\n",
    "except RuntimeError:\n",
    "    print(\"Stream ended\")\n",
    "        \n",
    "finally:\n",
    "    # Stop streaming\n",
    "    cv2.destroyAllWindows()\n",
    "    pipe.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "def remove_outliers(data, m=2):\n",
    "    # Z-score method\n",
    "    data = np.array(data)\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    filtered_data = [x for x in data if abs(x - mean) / std < m]\n",
    "    return filtered_data\n",
    "\n",
    "def calculate_mean_height(heights):\n",
    "    mean_heights = {}\n",
    "\n",
    "    for key, height_list in heights.items():\n",
    "        filtered_heights = remove_outliers(height_list)\n",
    "        if filtered_heights:\n",
    "            mean_heights[key] = np.mean(filtered_heights)\n",
    "\n",
    "    return mean_heights\n",
    "\n",
    "# Remove outliers and calculate the mean height for each aruco code id\n",
    "mean_heights = calculate_mean_height(heights)\n",
    "print(mean_heights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of frames:  696\n"
     ]
    }
   ],
   "source": [
    "colorizer = rs.colorizer()\n",
    "value_min = 0.0 # 0 meters\n",
    "value_max = 1.5 # 1.5 meters\n",
    "colorizer.set_option(rs.option.min_distance, value_min)\n",
    "colorizer.set_option(rs.option.max_distance, value_max)\n",
    "\n",
    "align = rs.align(rs.stream.color)\n",
    "\n",
    "file_name1 = \"..\\\\bag_records\\\\first.bag\"\n",
    "file_name2 = \"..\\\\bag_records\\\\second.bag\"\n",
    "pipe1, cfg1, profile1, playback1, frame_shape1 = read_bag_file(file_name1)\n",
    "pipe2, cfg2, profile2, playback2, frame_shape2 = read_bag_file(file_name2)\n",
    "num_frames = 0\n",
    "wait_key = 1\n",
    "\n",
    "color_images1 = []\n",
    "color_images2 = []\n",
    "save_images = False\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Get framesets of color and depth\n",
    "        frames1 = pipe1.wait_for_frames()\n",
    "        frames2 = pipe2.wait_for_frames()\n",
    "\n",
    "        # Align the depth frames to color frames\n",
    "        aligned_frames1 = align.process(frames1)\n",
    "        aligned_frames2 = align.process(frames2)\n",
    "\n",
    "        # Get aligned frames\n",
    "        aligned_depth_frame1 = aligned_frames1.get_depth_frame()\n",
    "        color_frame1 = aligned_frames1.get_color_frame()\n",
    "\n",
    "        aligned_depth_frame2 = aligned_frames2.get_depth_frame()\n",
    "        color_frame2 = aligned_frames2.get_color_frame()\n",
    "\n",
    "        # Validate that frames are valid\n",
    "        if not aligned_depth_frame1 or not color_frame1 or not aligned_depth_frame2 or not color_frame2:\n",
    "            continue\n",
    "\n",
    "        # Post process is not included in the BAG file, so we need to apply it\n",
    "        depth_frame1 = post_process_depth_frame(aligned_depth_frame1)\n",
    "        depth_frame2 = post_process_depth_frame(aligned_depth_frame2)\n",
    "\n",
    "        # Colorize the depth frames\n",
    "        depth_color_frame1 = colorizer.colorize(depth_frame1)\n",
    "        depth_color_frame2 = colorizer.colorize(depth_frame2)\n",
    "\n",
    "        depth_color_image1 = np.asanyarray(depth_color_frame1.get_data())\n",
    "        color_image1 = np.asanyarray(color_frame1.get_data())\n",
    "        depth_color_image2 = np.asanyarray(depth_color_frame2.get_data())\n",
    "        color_image2 = np.asanyarray(color_frame2.get_data())\n",
    "\n",
    "        # Stack the color images horizontally\n",
    "        color_image1 = cv2.resize(color_image1, (0, 0), fx = 0.7, fy = 0.7)\n",
    "        color_image2 = cv2.resize(color_image2, (0, 0), fx = 0.7, fy = 0.7)\n",
    "        color_images = np.hstack((color_image1, color_image2))\n",
    "\n",
    "        # Stack the depth images horizontally\n",
    "        depth_color_image1 = cv2.resize(depth_color_image1, (0, 0), fx = 0.7, fy = 0.7)\n",
    "        depth_color_image2 = cv2.resize(depth_color_image2, (0, 0), fx = 0.7, fy = 0.7)\n",
    "        depth_images = np.hstack((depth_color_image1, depth_color_image2))\n",
    "\n",
    "        if save_images:\n",
    "            color_images1.append(color_image1)\n",
    "            color_images2.append(color_image2)\n",
    "\n",
    "        cv2.imshow(\"Color Images\", color_images)\n",
    "        cv2.imshow(\"Depth Images\", depth_images)\n",
    "\n",
    "        key = cv2.waitKey(wait_key)\n",
    "\n",
    "        # Press esc close the image window\n",
    "        if key == 27:\n",
    "            break\n",
    "        \n",
    "        if key == ord('s'):\n",
    "            save_images = not save_images\n",
    "\n",
    "        # Press d to view the video frame by frame\n",
    "        if key == ord('d'):\n",
    "            if wait_key == 0:\n",
    "                wait_key = 1\n",
    "            else:\n",
    "                wait_key = 0\n",
    "\n",
    "        num_frames += 1\n",
    "\n",
    "# Catch exception if the stream is ended\n",
    "except RuntimeError:\n",
    "    print(\"Stream ended\")\n",
    "        \n",
    "finally:\n",
    "    # Stop streaming\n",
    "    cv2.destroyAllWindows()\n",
    "    pipe1.stop()\n",
    "    pipe2.stop()\n",
    "\n",
    "print(\"Total number of frames: \", num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for image1, image2 in zip(color_images1, color_images2):\n",
    "    cv2.imshow(\"Color Image 1\", image1)\n",
    "    cv2.imshow(\"Color Image 2\", image2)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attemping to enhance Aruco codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" camera_height = 2.65 # meters => NOT SURE ABOUT THIS VALUE\n",
    "\n",
    "pipe, cfg, profile, playback, frame_shape = read_bag_file(file_name)\n",
    "num_frames = 0\n",
    "wait_key = 1\n",
    "\n",
    "# Empty the distance_images folder\n",
    "files = glob.glob('distance_images/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "# Data structure to store the a list of height for every aruco code id\n",
    "heights = {}\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipe.wait_for_frames()\n",
    "\n",
    "        # Align the depth frame to color frame so they have the same shape\n",
    "        aligned_depth, aligned_color = align_frames(frames)\n",
    "        color_image = np.asanyarray(aligned_color.get_data())\n",
    "        depth_color_frame = colorizer.colorize(aligned_depth)\n",
    "        depth_color_image = np.asanyarray(depth_color_frame.get_data())\n",
    "\n",
    "        # Apply the mask to the depth image\n",
    "        depth_color_image = cv2.bitwise_and(depth_color_image, depth_color_image, mask=mask)\n",
    "\n",
    "        # Convert the image to HSV color space\n",
    "        hsv_image = cv2.cvtColor(depth_color_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Define the range for red color in HSV\n",
    "        # Note: Red can appear in two ranges in HSV\n",
    "        lower_red1 = np.array([0, 70, 50])\n",
    "        upper_red1 = np.array([10, 255, 255])\n",
    "        lower_red2 = np.array([170, 70, 50])\n",
    "        upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "        # Create masks for red color\n",
    "        red_mask1 = cv2.inRange(hsv_image, lower_red1, upper_red1)\n",
    "        red_mask2 = cv2.inRange(hsv_image, lower_red2, upper_red2)\n",
    "\n",
    "        # Combine the two masks\n",
    "        red_mask = cv2.bitwise_or(red_mask1, red_mask2)\n",
    "\n",
    "        # Apply the mask to the original image\n",
    "        result = cv2.bitwise_and(depth_color_image, depth_color_image, mask=red_mask)\n",
    "\n",
    "        # Convert the result to grayscale and apply thresholding\n",
    "        gray_result = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh_result = cv2.threshold(gray_result, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        # Apply the closing morphological operation to fill in holes\n",
    "        kernel = np.ones((30, 30), np.uint8)\n",
    "        closed_result = cv2.morphologyEx(thresh_result, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # Find contours of the red square\n",
    "        contours, _ = cv2.findContours(closed_result, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Create a mask to keep only the aruco code in the color image\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > 100*100 and area < 200*200:\n",
    "                x, y, w, h = cv2.boundingRect(contour)  \n",
    "                arcuo_code_mask = np.zeros(frame_shape, dtype=np.uint8)\n",
    "                \n",
    "                # Expand the bounding box by 50 pixels\n",
    "                sz = (w + h) // 2\n",
    "                x1 = max(0, x - 25)\n",
    "                y1 = max(0, y - 25)\n",
    "                x2 = min(640, x + sz + 25)\n",
    "                y2 = min(480, y + sz + 25)\n",
    "                cv2.rectangle(arcuo_code_mask, (x1, y1), (x2, y2), (255, 255, 255), -1)\n",
    "                color_image = cv2.bitwise_and(color_image, color_image, mask=arcuo_code_mask)\n",
    "\n",
    "                cv2.imwrite(\"color_images\\motion_blur_mask\\motion_blur\" + str(num_frames) + \".png\", color_image)\n",
    "\n",
    "        cv2.imshow(\"Output\", color_image)\n",
    "        key = cv2.waitKey(wait_key)\n",
    "\n",
    "        # Press esc close the image window\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "        # Press d to view the video frame by frame\n",
    "        if key == ord('d'):\n",
    "            if wait_key == 0:\n",
    "                wait_key = 1\n",
    "            else:\n",
    "                wait_key = 0\n",
    "\n",
    "        num_frames += 1\n",
    "           \n",
    "# Catch exception if the stream is ended\n",
    "except RuntimeError:\n",
    "    print(\"Stream ended\")\n",
    "        \n",
    "finally:\n",
    "    # Stop streaming\n",
    "    cv2.destroyAllWindows()\n",
    "    pipe.stop() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" image = cv2.imread(\"color_images\\motion_blur\\motion_blur1229.png\", cv2.IMREAD_GRAYSCALE)\n",
    "corners, ids, rejected = detector.detectMarkers(image)\n",
    "output_image = image.copy()\n",
    "if corners is not None:\n",
    "    print(\"Detected markers: \", len(corners))\n",
    "\n",
    "cv2.aruco.drawDetectedMarkers(output_image, corners, ids)\n",
    "cv2.imshow(\"Output\", output_image)\n",
    "\n",
    "# Show the marker id image\n",
    "marker_id = ids[0][0]\n",
    "print(\"Marker ID: \", marker_id)\n",
    "marker_size = 200  # Taille de l'image générée\n",
    "aruco_marker_image = cv2.aruco.generateImageMarker(aruco_dict, marker_id, marker_size)\n",
    "cv2.imshow(\"Marker\", aruco_marker_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
